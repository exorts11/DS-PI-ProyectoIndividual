{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\exort\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import copy as copy\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de los archivos\n",
    "ruta = \"./Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls(ruta = \"./Datasets\"):\n",
    "    return [arch.name for arch in os.scandir(ruta) if arch.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivos de origen predeterminados\n",
    "origin = np.array(['Clientes.csv',\n",
    " 'Compra.csv',\n",
    " 'Gasto.csv',\n",
    " 'Localidades.csv',\n",
    " 'Proveedores.csv',\n",
    " 'Sucursales.csv',\n",
    " 'TiposDeGasto.csv',\n",
    " 'Venta.csv'])\n",
    "codificacion = np.array(['utf-8','utf-8','utf-8','utf-8','ANSI','utf-8','utf-8','utf-8'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos que existen en el directorio\n",
    "archivos = np.array(ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Comprobar que archivos existen\n",
    "csv_existentes = np.array([False, False, False, False, False, False, False, False])\n",
    "excel_existe = False\n",
    "\n",
    "s = ''\n",
    "for word in archivos:\n",
    "    s += word\n",
    "\n",
    "idx = 0\n",
    "for frame_origin in origin :\n",
    "    if frame_origin in s:\n",
    "        csv_existentes[idx] = True\n",
    "    idx+=1\n",
    "\n",
    "# Comprobacion del excel\n",
    "if 'CanalDeVenta.xlsx' in s:\n",
    "    excel_existe = True\n",
    "\n",
    "print(csv_existentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(0,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CanalDeVenta.xlsx' 'Clientes.csv' 'Compra.csv' 'Gasto.csv'\n",
      " 'Localidades.csv' 'Proveedores.csv' 'Sucursales.csv' 'TiposDeGasto.csv'\n",
      " 'Venta.csv']\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las tablas csv en una lista\n",
    "u = 0\n",
    "for i in origin:\n",
    "    if csv_existentes[u]:\n",
    "        r = ruta+i\n",
    "        g = open(r,encoding=codificacion[u])\n",
    "        n = 1\n",
    "        for i in g:\n",
    "            #print(i)\n",
    "            if ',' in i:\n",
    "                #print('Delimiter coma')\n",
    "                data[u] = (pd.read_csv(r,encoding=codificacion[u]))\n",
    "            else:\n",
    "                #print('delimiter punto y coma')\n",
    "                data[u] = (pd.read_csv(r,delimiter=';',encoding=codificacion[u]))\n",
    "            break\n",
    "        #print(u,r)\n",
    "        g.close()\n",
    "    u+=1\n",
    "\n",
    "print(archivos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos = copy.copy(origin[csv_existentes == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clientes.csv' 'Compra.csv' 'Gasto.csv' 'Localidades.csv'\n",
      " 'Proveedores.csv' 'Sucursales.csv' 'TiposDeGasto.csv' 'Venta.csv'\n",
      " 'CanalDeVenta.xls']\n"
     ]
    }
   ],
   "source": [
    "# Actualizamos la variable archivos\n",
    "\n",
    "# Cargamos el excel, si existe\n",
    "if excel_existe:\n",
    "    data.append(pd.read_excel(ruta+'CanalDeVenta.xlsx'))\n",
    "    archivos = np.append(archivos,['CanalDeVenta.xls'])\n",
    "print(archivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO</th>\n",
       "      <th>DESCRIPCION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Telefónica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OnLine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Presencial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODIGO DESCRIPCION\n",
       "0       1  Telefónica\n",
       "1       2      OnLine\n",
       "2       3  Presencial"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogenizar el nombre de los campos ID de cada tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, table in enumerate(data):\n",
    "    name = 'ID_'+archivos[idx][:-4]\n",
    "    data[idx].rename(columns={table.columns[0] : name}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogenizar el nombre de los campos de latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].rename(columns={data[0].columns[-3] : 'Longitud',data[0].columns[-2] : 'Latitud'}, inplace=True)\n",
    "data[3].rename(columns={data[3].columns[2] : 'Longitud',data[3].columns[1] : 'Latitud'}, inplace=True)\n",
    "data[-4].rename(columns={data[-4].columns[6] : 'Longitud',data[-4].columns[5] : 'Latitud'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir las columnas de latitud y longitud a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_3964\\1552489187.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[df][col].iloc[idx] = float(data[df][col].iloc[idx].replace(',','.'))\n"
     ]
    }
   ],
   "source": [
    "tablas = [0,3,-4]\n",
    "campos = ['Longitud','Latitud']\n",
    "for df in tablas:\n",
    "    for col in campos:\n",
    "        #df.Y = df.Y.replace(np.nan,80.5)\n",
    "        #df.Y = df.Y.astype(str)\n",
    "        data[df][col] = data[df][col].replace(np.nan,80.5).copy()\n",
    "        data[df][col] = data[df][col].astype(str)\n",
    "\n",
    "    #for idx in df.index:\n",
    "    #    if type(df.Y.iloc[idx]) != float:\n",
    "    #        df.Y.iloc[idx] = float(df.Y.iloc[idx].replace(',','.'))\n",
    "        for idx in data[df].index:\n",
    "            try:\n",
    "                if type(data[df][col].iloc[idx]) != float:\n",
    "                    data[df][col].iloc[idx] = float(data[df][col].iloc[idx].replace(',','.'))\n",
    "            except:\n",
    "                print(df,col,idx)\n",
    "                break\n",
    "        \n",
    "        data[df][col] = data[df][col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla del precio medio de los productos de la tabla Compra y Ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_3964\\3183647966.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[t1[count]].Precio.iloc[i] = precio_medio[productos == data[t1[count]].IdProducto.iloc[i]]\n",
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_3964\\3183647966.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[t1[count]].Precio.iloc[i] = precio_medio[productos == data[t1[count]].IdProducto.iloc[i]]\n"
     ]
    }
   ],
   "source": [
    "# Tablas base\n",
    "t = np.array(['Compra.csv','Venta.csv'])\n",
    "t1 = [1,-2]\n",
    "count = 0\n",
    "for tablas in t:\n",
    "    if tablas in archivos:\n",
    "        # Valores unicos en el IdProducto en la tabla compras\n",
    "        productos = data[t1[count]].IdProducto.unique()\n",
    "        precio_medio = np.zeros((data[t1[count]].IdProducto.unique().shape[0],1))\n",
    "\n",
    "        # Obtenemos el precio medio\n",
    "        for idx, product in enumerate(productos):\n",
    "            precio_medio[idx] = data[t1[count]].Precio[data[t1[count]].IdProducto == product].median()\n",
    "\n",
    "        # Sustituimos el nulo por el precio medio\n",
    "        for i in data[t1[count]][data[t1[count]].Precio.isnull() == True].index:\n",
    "            data[t1[count]].Precio.iloc[i] = precio_medio[productos == data[t1[count]].IdProducto.iloc[i]]\n",
    "\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el nombre de la columna state a provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4].rename(columns={data[4].columns[4] : 'provincia_nombre'}, inplace=True)\n",
    "data[0].rename(columns={data[0].columns[1] : 'provincia_nombre'}, inplace=True)\n",
    "data[-4].rename(columns={data[-4].columns[4] : 'provincia_nombre'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtein para normalizar el nombre de la provincia en todas las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov = data[3].provincia_nombre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].provincia_nombre = data[0].provincia_nombre.fillna('xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_3964\\1898526236.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[table].provincia_nombre.iloc[row] = prov[levenshtein == levenshtein.max()][0]\n"
     ]
    }
   ],
   "source": [
    "t1 = [0,4,-4]\n",
    "levenshtein = np.zeros((23,1))\n",
    "levenshtein = levenshtein.sum(axis=1)\n",
    "for table in t1:\n",
    "    for row in data[table].index:\n",
    "        if data[table].provincia_nombre.iloc[row] != 'xxxx':\n",
    "            for idx, provincia in enumerate(prov):\n",
    "                levenshtein[idx] = fuzz.token_set_ratio(data[table].provincia_nombre.iloc[row], provincia)\n",
    "            #print(levenshtein)\n",
    "            data[table].provincia_nombre.iloc[row] = prov[levenshtein == levenshtein.max()][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar el campo departamento en proveedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prov = data[3].departamento_nombre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#levenshtein = np.zeros((prov.shape[0],1))\n",
    "#levenshtein = levenshtein.sum(axis=1)\n",
    "#for row in data[-5].index:\n",
    "#    for idx, departamento in enumerate(prov):\n",
    "#        levenshtein[idx] = fuzz.token_set_ratio(data[-5].departamen.iloc[row], departamento)\n",
    "    #print(levenshtein)\n",
    "#    data[-5].departamen.iloc[row] = prov[levenshtein == levenshtein.max()][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar el campo localidad en tabla sucursales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_3964\\2148845363.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[-4].Localidad.iloc[row] = prov[levenshtein == levenshtein.max()][0]\n",
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_3964\\2148845363.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[-5].City.iloc[row] = prov[levenshtein == levenshtein.max()][0]\n"
     ]
    }
   ],
   "source": [
    "# Tabla sucursales\n",
    "prov = data[3].nombre.unique()\n",
    "levenshtein = np.zeros((prov.shape[0],1))\n",
    "levenshtein = levenshtein.sum(axis=1)\n",
    "for row in data[-4].index:\n",
    "    for idx, localidad in enumerate(prov):\n",
    "        levenshtein[idx] = fuzz.token_set_ratio(data[-4].Localidad.iloc[row], localidad)\n",
    "    #print(levenshtein)\n",
    "    data[-4].Localidad.iloc[row] = prov[levenshtein == levenshtein.max()][0]\n",
    "\n",
    "# Tabla proveedores\n",
    "for row in data[-5].index:\n",
    "    for idx, localidad in enumerate(prov):\n",
    "        levenshtein[idx] = fuzz.token_set_ratio(data[-5].City.iloc[row], localidad)\n",
    "    #print(levenshtein)\n",
    "    data[-5].City.iloc[row] = prov[levenshtein == levenshtein.max()][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlayers en las tablas Compra, Venta y Gasto, columna Precio y Monto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = [1,-2]\n",
    "zCompra = 0\n",
    "zVenta = 0\n",
    "for tabla in t1:\n",
    "    # Calcular los rangos intercuartilicos para cada IdProducto\n",
    "    prov = data[tabla].IdProducto.unique()\n",
    "    rango = np.zeros((data[tabla].IdProducto.unique().shape[0],2))\n",
    "    for idx, producto in enumerate(prov):\n",
    "        p25 = np.percentile(data[tabla].Precio[data[tabla].IdProducto == producto],25)\n",
    "        p75 = np.percentile(data[tabla].Precio[data[tabla].IdProducto == producto],75)\n",
    "        r = p75-p25\n",
    "        m = data[tabla].Precio[data[tabla].IdProducto == producto].median()\n",
    "        \n",
    "        # Contar el numero de outlayers\n",
    "        if tabla == 1:\n",
    "            zCompra += data[tabla].Precio[(data[tabla].IdProducto == producto) & (data[tabla].Precio < p25-1.5*r)].shape[0]\n",
    "            zCompra += data[tabla].Precio[(data[tabla].IdProducto == producto) & (data[tabla].Precio > p75+1.5*r)].shape[0]\n",
    "        else:\n",
    "            zVenta += data[tabla].Precio[(data[tabla].IdProducto == producto) & (data[tabla].Precio < p25-1.5*r)].shape[0]\n",
    "            zVenta += data[tabla].Precio[(data[tabla].IdProducto == producto) & (data[tabla].Precio > p75+1.5*r)].shape[0]\n",
    "\n",
    "        data[tabla].Precio[(data[tabla].IdProducto == producto) & (data[tabla].Precio < p25-1.5*r)] = copy.copy(m)\n",
    "        data[tabla].Precio[(data[tabla].IdProducto == producto) & (data[tabla].Precio > p75+1.5*r)] = copy.copy(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zGasto = 0\n",
    "tabla = 2\n",
    "prov = data[tabla].IdTipoGasto.unique()\n",
    "rango = np.zeros((data[tabla].IdTipoGasto.unique().shape[0],2))\n",
    "for idx, producto in enumerate(prov):\n",
    "    p25 = np.percentile(data[tabla].Monto[data[tabla].IdTipoGasto == producto],25)\n",
    "    p75 = np.percentile(data[tabla].Monto[data[tabla].IdTipoGasto == producto],75)\n",
    "    r = p75-p25\n",
    "    m = data[tabla].Monto[data[tabla].IdTipoGasto == producto].median()\n",
    "\n",
    "    # cantidad de outlayers\n",
    "    zGasto += data[tabla].Monto[(data[tabla].IdTipoGasto == producto) & (data[tabla].Monto < p25-1.5*r)].shape[0]\n",
    "    zGasto += data[tabla].Monto[(data[tabla].IdTipoGasto == producto) & (data[tabla].Monto > p75+1.5*r)].shape[0]\n",
    "\n",
    "    data[tabla].Monto[(data[tabla].IdTipoGasto == producto) & (data[tabla].Monto < p25-1.5*r)] = copy.copy(m)\n",
    "    data[tabla].Monto[(data[tabla].IdTipoGasto == producto) & (data[tabla].Monto > p75+1.5*r)] = copy.copy(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015772597278793658\n",
      "0.017821567778258985\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de outlayers\n",
    "\n",
    "print(zCompra/data[1].shape[0])\n",
    "print(zVenta/data[-2].shape[0])\n",
    "print(zGasto/data[2].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar tablas para crear relaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Buenos Aires', 'Catamarca', 'Córdoba', 'Corrientes', 'Chaco',\n",
       "       'Chubut', 'Entre Ríos', 'Formosa', 'Jujuy', 'La Pampa', 'La Rioja',\n",
       "       'Mendoza', 'Misiones', 'Neuquén', 'Río Negro', 'Salta', 'San Juan',\n",
       "       'San Luis', 'Santa Cruz', 'Santa Fe', 'Santiago del Estero',\n",
       "       'Tucumán', 'Tierra del Fuego, Antártida e Islas del Atlántico Sur'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3].provincia_nombre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Buenos Aires' 'Catamarca' 'Córdoba' 'Corrientes' 'Chaco' 'Chubut'\n",
      " 'Entre Ríos' 'Formosa' 'Jujuy' 'La Pampa' 'La Rioja' 'Mendoza' 'Misiones'\n",
      " 'Neuquén' 'Río Negro' 'Salta' 'San Juan' 'San Luis' 'Santa Cruz'\n",
      " 'Santa Fe' 'Santiago del Estero' 'Tucumán'\n",
      " 'Tierra del Fuego, Antártida e Islas del Atlántico Sur']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_10244\\1525818419.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  provincias.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Tabla de provincias\n",
    "provincias = data[3][['provincia_id','provincia_nombre']]\n",
    "provincias.drop_duplicates(inplace=True)\n",
    "print(provincias.provincia_nombre.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].drop(columns='col10',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear y volver a cargar csv de Canal de venta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas = [data[8],data[0],data[4],data[5],data[6],data[1],data[7],data[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar las tablas a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectandome a la base de datos\n",
    "import mysql.connector\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host='localhost',\n",
    "                                       database='proyectoIndividual',\n",
    "                                       user='root',\n",
    "                                       password='root')\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subir Canal de venta\n",
    "for idx in tablas[0].index:\n",
    "    cur.execute('''insert ignore into CanalDeVenta (ID_CanalDeVenta, DESCRIPCION)\n",
    "        VALUES ( %s, %s )''', ( str(data[8].ID_CanalDeVenta[idx]), data[8].DESCRIPCION[idx] ) )\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_10244\\1065197095.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  values[idx] = str(i)\n"
     ]
    }
   ],
   "source": [
    "# Update Clientes\n",
    "for idx in tablas[1].index:\n",
    "    values = tablas[1].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        values[idx] = str(i)\n",
    "    cur.execute('''insert ignore into Clientes (ID_Clientes,provincia_nombre,Nombre_y_Apellido,Domicilio,Telefono,Edad,Localidad,Longitud,Latitud)\n",
    "        values (%s,%s,%s,%s,%s,%s,%s,%s,%s)   ''', list(values.values))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_17052\\3016672941.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  values[idx] = str(i)\n"
     ]
    }
   ],
   "source": [
    "# Update Proveedores\n",
    "#['ID_Proveedores', 'Nombre', 'Address', 'Localidad', 'Country', 'departamen']\n",
    "for idx in tablas[2].index:\n",
    "    values = tablas[2].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        if idx == 0:\n",
    "            values[idx] = str(i)\n",
    "    try :cur.execute('''insert ignore into Proveedores (ID_Proveedores,Nombre,Address,Localidad,Country,departamen)\n",
    "        values (%s,%s,%s,%s,%s,%s)   ''', list(values.values))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_17052\\1262318636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  values[idx] = str(i)\n"
     ]
    }
   ],
   "source": [
    "# Update Sucursales\n",
    "#['ID_Sucursales', 'Sucursal', 'Direccion', 'Localidad', 'Latitud', 'Longitud']\n",
    "for idx in tablas[3].index:\n",
    "    values = tablas[3].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        values[idx] = str(i)\n",
    "    cur.execute('''insert ignore into Sucursales (ID_Sucursales,Sucursal,Direccion,Localidad,Latitud,Longitud)\n",
    "        values (%s,%s,%s,%s,%s,%s)   ''', list(values.values))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_17052\\2933209138.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  values[idx] = str(i)\n"
     ]
    }
   ],
   "source": [
    "# Update TiposDeGasto\n",
    "# ['ID_TiposDeGasto', 'Descripcion', 'Monto_Aproximado']\n",
    "\n",
    "for idx in tablas[4].index:\n",
    "    values = tablas[4].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        values[idx] = str(i)\n",
    "    cur.execute('''insert ignore into TiposDeGasto (ID_TiposDeGasto,Descripcion,Monto_Aproximado)\n",
    "        values (%s,%s,%s)   ''', list(values.values))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_17052\\2535455300.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  values[idx] = str(i)\n"
     ]
    }
   ],
   "source": [
    "# Update Compra\n",
    "# ['ID_Compra', 'Fecha', 'Fecha_Año', 'Fecha_Mes', 'Fecha_Periodo', 'IdProducto', 'Cantidad', 'Precio', 'IdProveedor']\n",
    "\n",
    "for idx in tablas[5].index:\n",
    "    values = tablas[5].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        values[idx] = str(i)\n",
    "    cur.execute('''insert ignore into Compra (ID_Compra,Fecha,Fecha_Año,Fecha_Mes,Fecha_Periodo,IdProducto,Cantidad,Precio,IdProveedor)\n",
    "        values (%s,%s,%s,%s,%s,%s,%s,%s,%s)   ''', list(values.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Venta\n",
    "# ['ID_Venta', 'Fecha', 'Fecha_Entrega', 'IdCanal', 'IdCliente', 'IdSucursal', 'IdEmpleado', 'IdProducto', 'Precio', 'Cantidad']\n",
    "\n",
    "for idx in tablas[6].index:\n",
    "    values = tablas[6].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        values[idx] = str(i)\n",
    "    cur.execute('''insert ignore into Venta (ID_Venta, Fecha, Fecha_Entrega, IdCanal, IdCliente, IdSucursal, IdEmpleado, IdProducto, Precio, Cantidad)\n",
    "        values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)   ''', list(values.values))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exort\\AppData\\Local\\Temp\\ipykernel_10244\\4126853511.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  values[idx] = str(i)\n"
     ]
    }
   ],
   "source": [
    "# Update Gasto\n",
    "# ['ID_Gasto', 'IdSucursal', 'IdTipoGasto', 'Fecha', 'Monto']\n",
    "\n",
    "for idx in tablas[7].index:\n",
    "    values = tablas[7].iloc[idx]\n",
    "    for idx,i in enumerate(values):\n",
    "        values[idx] = str(i)\n",
    "    cur.execute('''insert ignore into Gasto (ID_Gasto,IdSucursal,IdTipoGasto,Fecha,Monto)\n",
    "        values (%s,%s,%s,%s,%s)   ''', list(values.values))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Clientes.csv', 'Compra.csv', 'Gasto.csv', 'Localidades.csv',\n",
       "       'Proveedores.csv', 'Sucursales.csv', 'TiposDeGasto.csv',\n",
       "       'Venta.csv', 'CanalDeVenta.xls'], dtype='<U16')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_Clientes', 'provincia_nombre', 'Nombre_y_Apellido', 'Domicilio', 'Telefono', 'Edad', 'Localidad', 'Longitud', 'Latitud']\n",
      "['ID_Compra', 'Fecha', 'Fecha_Año', 'Fecha_Mes', 'Fecha_Periodo', 'IdProducto', 'Cantidad', 'Precio', 'IdProveedor']\n",
      "['ID_Gasto', 'IdSucursal', 'IdTipoGasto', 'Fecha', 'Monto']\n",
      "['ID_Localidades', 'Latitud', 'Longitud', 'departamento_id', 'departamento_nombre', 'fuente', 'id', 'localidad_censal_id', 'localidad_censal_nombre', 'municipio_id', 'municipio_nombre', 'nombre', 'provincia_id']\n",
      "['ID_Proveedores', 'Nombre', 'Address', 'Localidad', 'Country', 'departamen']\n",
      "['ID_Sucursales', 'Sucursal', 'Direccion', 'Localidad', 'Latitud', 'Longitud']\n",
      "['ID_TiposDeGasto', 'Descripcion', 'Monto_Aproximado']\n",
      "['ID_Venta', 'Fecha', 'Fecha_Entrega', 'IdCanal', 'IdCliente', 'IdSucursal', 'IdEmpleado', 'IdProducto', 'Precio', 'Cantidad']\n",
      "['ID_CanalDeVenta', 'DESCRIPCION']\n"
     ]
    }
   ],
   "source": [
    "#for idx, table in enumerate(data):\n",
    "#    print(list(table.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89f8f4da03b88366b24b3e615f25203f75fc591e3c4bb5e4e10f1e65da1c83de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
